package metoClassifier;

import java.io.Serializable;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;

import utils.BrownCluster_Str;
import utils.Embeddings_Vec;
import utils.Levin;

import libsvm.svm_node;
import model.Dependency;
import model.Document;
import model.Feature;
import model.Global;
import model.NamedEntity;
import model.NominalFeature;
import model.Sentence;
import model.Word;

public class FeatureExtractor implements Serializable {

	/**
	 * 
	 */
	private static final long serialVersionUID = 1L;

	String[] featureHeads = { "parse" }; // default is the parse feature only.

	int fValLen;

	public int getFValLen() {
		return this.fValLen;
	}

	public FeatureExtractor(String... heads) {
		this.featureHeads = heads;
		System.err.println("Feautre Value Length is set to 0, "
				+ "then it's not checked for consistancy with feature length generated by feature extractor.");
	}

	public FeatureExtractor(int fValLen, String... heads) {
		this.featureHeads = heads;
		this.fValLen = fValLen;
	}

	public ArrayList<ArrayList<svm_node>> extract(ArrayList<Document> docs) throws Exception {

		if (docs == null)
			return null;
		if (docs.size() == 0)
			return null;

		ArrayList<ArrayList<svm_node>> features = null;

		for (String featureHead : featureHeads) {
			ArrayList<ArrayList<svm_node>> feature = null;
			if (featureHead.equals("context")) {
				feature = extractContextFeature(docs);
			}
			if (featureHead.equals("determiner")) {
				feature = extractDeterminerFeature(docs);
			}
			if (featureHead.equals("parse")) {
				feature = extractParseFeature(docs);
			}
			if (features == null)
				features = feature;
			else {
				for (int i = 0; i < feature.size(); i++) {
					features.get(i).addAll(feature.get(i));
				}
			}
		}

		return features;

	}

	private ArrayList<ArrayList<svm_node>> extractDeterminerFeature(ArrayList<Document> docs) {

		ArrayList<ArrayList<svm_node>> features = new ArrayList<ArrayList<svm_node>>();

		for (Document doc : docs) {
			List<Sentence> sents = doc.getParagraphs().get(0).getSentences();
			for (Sentence sent : sents) {
				if (sent.getEntities().size() != 0) {
					NamedEntity ne = sent.getNamedEntities().get(0);
					int s = ne.getStart();
					int e = ne.getEnd();
					boolean determiner = false;

					// add -1 word
					if (s >= 2)
						determiner = utils.StringUtils.isDeterminer(sent.getWords().get(s - 2).getWord());
					if (s >= 1)
						determiner = utils.StringUtils.isDeterminer(sent.getWords().get(s - 1).getWord());
					ArrayList<svm_node> nodes = new ArrayList<svm_node>();
					nodes.add(new svm_node());
					nodes.get(0).index = 0;
					nodes.get(0).value = determiner ? 1 : 0;
					features.add(nodes);
					System.out.println(determiner);
				}
			}
		}
		return features;
	}

	private ArrayList<ArrayList<svm_node>> extractParseFeature(ArrayList<Document> docs) throws Exception {

		ArrayList<ArrayList<svm_node>> features = new ArrayList<ArrayList<svm_node>>();

		NominalFeature frelations = new NominalFeature("Feature: Parse:tRelations");
		NominalFeature ftarget = new NominalFeature("Feature: Parse:target");

		for (Document doc : docs) {
			ArrayList<svm_node> feat = new ArrayList<svm_node>();
			String t = "[N/A]", s = "[N/A]", relt = "[N/A]", rels = "[N/A]";
			for (Sentence sent : doc.getParagraphs().get(0).getSentences()) {
				if (sent.getEntities().size() == 0)
					continue;
				NamedEntity ne = sent.getNamedEntities().get(0);
				Word head = ne.getLastWord();

				for (Dependency dep : sent.getP()) {
					Word src = dep.getSource();
					Word tgt = dep.getTarget();
					String rel = dep.getRelation();
					if (src.equals(head)) {
						t = tgt.getLemma();
						relt = rel;
					} else if (tgt.equals(head)) {
						rels = rel;
						s = src.getLemma();
					}
					frelations.addFeatureValue(relt);
					frelations.addFeatureValue(rels);
					ftarget.addFeatureValue(t);
					ftarget.addFeatureValue(s);
				}
				
			}

		}

		for (Document doc : docs) {
			ArrayList<svm_node> feat = new ArrayList<svm_node>();
			String t = "[N/A]", s = "[N/A]", relt = "[N/A]", rels = "[N/A]";
			for (Sentence sent : doc.getParagraphs().get(0).getSentences()) {
				if (sent.getEntities().size() == 0)
					continue;
				NamedEntity ne = sent.getNamedEntities().get(0);
				Word head = ne.getLastWord();

				for (Dependency dep : sent.getP()) {
					Word src = dep.getSource();
					Word tgt = dep.getTarget();
					String rel = dep.getRelation();
					if (src.equals(head)) {
						t = tgt.getLemma();
						relt = rel;
					} else if (tgt.equals(head)) {
						rels = rel;
						s = src.getLemma();
					}
				}
				feat.addAll(ftarget.getSVMNodeVector(new String[]{t,s}));
				feat.addAll(frelations.getSVMNodeVector(new String[]{relt,rels}));
				features.add(feat);
			}

		}
		return features;
	}

	private ArrayList<ArrayList<svm_node>> extractContextFeature(ArrayList<Document> docs) throws Exception {

		ArrayList<ArrayList<svm_node>> features = new ArrayList<ArrayList<svm_node>>();

		NominalFeature fctxt = new NominalFeature("Feature: contextwords");

		for (Document doc : docs) {
			List<Sentence> sents = doc.getParagraphs().get(0).getSentences();
			for (Sentence sent : sents) {
				if (sent.getEntities().size() != 0) {
					NamedEntity ne = sent.getNamedEntities().get(0);
					int s = ne.getStart();
					int e = ne.getEnd();
					String p3 = "[N/A]", p2 = "[N/A]", p1 = "[N/A]", n1 = "[N/A]", n2 = "[N/A]", n3 = "[N/A]";

					if (s >= 3) {
						p3 = sent.getWords().get(s - 3).getLemma();
					}
					if (s >= 2) {
						p2 = sent.getWords().get(s - 2).getLemma();
					}
					if (s >= 1) {
						p1 = sent.getWords().get(s - 1).getLemma();
					}
					if (e < sent.getWords().size() - 1) {
						n1 = sent.getWords().get(e + 1).getLemma();
					}
					if (e < sent.getWords().size() - 2) {
						n2 = sent.getWords().get(e + 2).getLemma();
					}
					if (e < sent.getWords().size() - 3) {
						n3 = sent.getWords().get(e + 3).getLemma();
					}
					fctxt.addFeatureValue(p3);
					fctxt.addFeatureValue(p2);
					fctxt.addFeatureValue(p1);
					fctxt.addFeatureValue(n1);
					fctxt.addFeatureValue(n2);
//					fctxt.addFeatureValue(n3);

				}
			}
		}

		for (Document doc : docs) {
			List<Sentence> sents = doc.getParagraphs().get(0).getSentences();
			for (Sentence sent : sents) {
				if (sent.getEntities().size() != 0) {
					NamedEntity ne = sent.getNamedEntities().get(0);
					int s = ne.getStart();
					int e = ne.getEnd();
					String p3 = "[N/A]", p2 = "[N/A]", p1 = "[N/A]", n1 = "[N/A]", n2 = "[N/A]", n3 = "[N/A]";
					if (s >= 3)
						p3 = sent.getWords().get(s - 3).getLemma();
					if (s >= 2)
						p2 = sent.getWords().get(s - 2).getLemma();
					if (s >= 1)
						p1 = sent.getWords().get(s - 1).getLemma();
					if (e < sent.getWords().size() - 1) {
						n1 = sent.getWords().get(e + 1).getLemma();
					}
					if (e < sent.getWords().size() - 2) {
						n2 = sent.getWords().get(e + 2).getLemma();
					}
					if (e < sent.getWords().size() - 3) {
						n3 = sent.getWords().get(e + 3).getLemma();
					}

					// One Hot Coding
//					String[] keys = new String[] { p3, p2, p1, n1, n2, n3 };	
//					features.add(fctxt.getSVMNodeVector(keys));
					
					// word embeddings
					ArrayList<svm_node> feat = new ArrayList<svm_node>();
					feat.addAll(Embeddings_Vec.getEmbeddingSVMNodes(p2));
					feat.addAll(Embeddings_Vec.getEmbeddingSVMNodes(p1));
					feat.addAll(Embeddings_Vec.getEmbeddingSVMNodes(n1));
					feat.addAll(Embeddings_Vec.getEmbeddingSVMNodes(n2));
					features.add(feat);
				}
			}// end sent loop
		}// end doc loop

		return features;
	}
}
